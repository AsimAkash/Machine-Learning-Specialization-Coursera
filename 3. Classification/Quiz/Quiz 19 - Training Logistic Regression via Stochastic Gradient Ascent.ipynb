{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 19 - Training Logistic Regression via Stochastic Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_13 Questions_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Are you using GraphLab Create? Please make sure that\n",
    "\n",
    "1. You are using version 1.8.3 of GraphLab Create. Verify the version of GraphLab Create by running **graphlab.version** inside the notebook. If your GraphLab version is incorrect, see this post to install version 1.8.3. This assignment is not guaranteed to work with other versions of GraphLab Create.\n",
    "\n",
    "2. You are using the IPython notebook named module-3-linear-classifier-learning-assignment-blank.ipynb obtained from the associated reading.\n",
    "\n",
    "This question is ungraded. Check one of the three options to confirm.\n",
    "\n",
    "* I confirm that I am using the right version of GraphLab Create and the right IPython notebook.\n",
    "\n",
    "* I am using SFrame and NumPy only.\n",
    "\n",
    "* I am using other tools, and I understand that I may not be able to complete some of the quiz questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In Module 3 assignment, there were 194 features (an intercept + one feature for each of the 193 important words). In this assignment, we will use stochastic gradient ascent to train the classifier using logistic regression. How does the changing the solver to stochastic gradient ascent affect the number of features?\n",
    "\n",
    "* A. Increases\n",
    "\n",
    "* B. Decreases\n",
    "\n",
    "* C. Stays the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recall from the lecture and the earlier assignment, the log likelihood (without the averaging term) is given by\n",
    "\n",
    "<img src=\"images/image_19_1.png\">\n",
    "\n",
    "### whereas the average log likelihood is given by\n",
    "\n",
    "<img src=\"images/image_19_2.png\">\n",
    "\n",
    "### How are the functions ll(w) and ll_A(w) related?\n",
    "\n",
    "* A. ll_A(w) = ll(w)\n",
    "\n",
    "* B. ll_A(w) = (1/N)*ll(w)\n",
    "\n",
    "* C. ll_A(w) = N*ll(w)\n",
    "\n",
    "* D. ll_A(w) = ll(w) - ∥w∥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Refer to the sub-section Computing the gradient for a single data point.\n",
    "\n",
    "The code block above computed\n",
    "\n",
    "<img src=\"images/image_19_3.png\">\n",
    "\n",
    "### for j = 1 and i = 10. Is this quantity a scalar or a 194-dimensional vector?\n",
    "\n",
    "* A. A scalar\n",
    "\n",
    "* B. A 194-dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Refer to the sub-section Modifying the derivative for using a batch of data points.\n",
    "\n",
    "The code block computed\n",
    "\n",
    "<img src=\"images/image_19_4.png\">\n",
    "\n",
    "### for j = 10, i = 10, and B = 10. Is this a scalar or a 194-dimensional vector?\n",
    "\n",
    "* A. A scalar\n",
    "\n",
    "* B. A 194-dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For what value of B is the term\n",
    "\n",
    "<img src=\"images/image_19_5.png\">\n",
    "\n",
    "the same as the full gradient\n",
    "\n",
    "<img src=\"images/image_19_6.png\">\n",
    "\n",
    "### A numeric answer is expected for this question. Hint: consider the training set we are using now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For what value of batch size B above is the stochastic gradient ascent function logistic_regression_SG act as a standard gradient ascent algorithm? A numeric answer is expected for this question. Hint: consider the training set we are using now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. When you set batch_size = 1, as each iteration passes, how does the average log likelihood in the batch change?\n",
    "\n",
    "* A. Increases\n",
    "\n",
    "* B. Decreases\n",
    "\n",
    "* C. Fluctuates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. When you set batch_size = len(train_data), as each iteration passes, how does the average log likelihood in the batch change?\n",
    "\n",
    "* A. Increases\n",
    "\n",
    "* B. Decreases\n",
    "\n",
    "* C. Fluctuates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Suppose that we run stochastic gradient ascent with a batch size of 100. How many gradient updates are performed at the end of two passes over a dataset consisting of 50000 data points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Refer to the section Stochastic gradient ascent vs gradient ascent.\n",
    "\n",
    "### In the first figure, how many passes does batch gradient ascent need to achieve a similar log likelihood as stochastic gradient ascent?\n",
    "\n",
    "* A. It's always better\n",
    "\n",
    "* B. 10 passes\n",
    "\n",
    "* C. 20 passes\n",
    "\n",
    "* D. 150 passes or more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 11 and 12 refer to the section Plotting the log likelihood as a function of passes for each step size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Which of the following is the worst step size? Pick the step size that results in the lowest log likelihood in the end.\n",
    "\n",
    "* A. 1e-2\n",
    "\n",
    "* B. 1e-1\n",
    "\n",
    "* C. 1e0\n",
    "\n",
    "* D. 1e1\n",
    "\n",
    "* E. 1e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Which of the following is the best step size? Pick the step size that results in the highest log likelihood in the end.\n",
    "\n",
    "* A. 1e-4\n",
    "\n",
    "* B. 1e-2\n",
    "\n",
    "* C. 1e0\n",
    "\n",
    "* D. 1e1\n",
    "\n",
    "* E. 1e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
